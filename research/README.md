## Research Models

### Computer Vision

#### Image Classification

| model                   | paper                                                        |                      vanilla mindspore                       |
| :---------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| lenet                   | [Gradient-Based Learning Applied to Document Recognition](https://ieeexplore.ieee.org/document/726791) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/lenet) |
| googlenet               | [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/googlenet) |
| inception_resnet_v2     | [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/inception_resnet_v2) |
| inceptionv2             | [Rethinking the Inception Architecture for Computer Vision](https://arxiv.org/abs/1512.00567) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Inception-v2) |
| nasnet                  | [Learning Transferable Architectures for Scalable Image Recognition](https://arxiv.org/abs/1707.07012) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/nasnet) |
| densenet100             | [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/densenet) |
| densenet121             | [Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/densenet) |
| dpn                     | [Dual Path Networks](https://arxiv.org/abs/1707.01629)       | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/dpn) |
| efficientnet-b0         | [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DRNet) |
| mobilenetv3_large       | [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/mobilenetv3_large) |
| mobilenetV3_small_x1_0  | [Searching for MobileNetV3](https://arxiv.org/abs/1905.02244) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/mobilenetV3_small_x1_0) |
| squeezenet              | [SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size](https://arxiv.org/abs/1602.07360) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/squeezenet) |
| ghostnet                | [GhostNet: More Features from Cheap Operations](https://arxiv.org/abs/1911.11907) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ghostnet) |
| ghostnet_d              | [GhostNets on Heterogeneous Devices via Cheap Operations](https://arxiv.org/abs/2201.03297) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ghostnet_d) |
| tinydarknet             | [You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tinydarknet) |
| sppnet                  | [Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition](https://arxiv.org/abs/1406.4729) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SPPNet) |
| res2net101              | [Res2Net: A New Multi-scale Backbone Architecture](https://arxiv.org/abs/1904.01169) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net) |
| res2net152              | [Res2Net: A New Multi-scale Backbone Architecture](https://arxiv.org/abs/1904.01169) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net) |
| res2net50               | [Res2Net: A New Multi-scale Backbone Architecture](https://arxiv.org/abs/1904.01169) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net) |
| resnext50               | [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ResNeXt) |
| resnest50               | [ResNeSt: Split-Attention Networks](https://arxiv.org/abs/2004.08955) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ResNeSt50) |
| resnet50_adv_pruning    | [SCOP: Scientific Control for Reliable Neural Network Pruning](https://arxiv.org/abs/2010.10732) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnet50_adv_pruning) |
| resnet50_bam            | [BAM: Bottleneck Attention Module](https://arxiv.org/abs/1807.06514) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnet50_bam) |
| resnet50-quadruplet     | [Beyond triplet loss: A deep quadruplet network for person re-identification](https://arxiv.org/abs/1704.01719) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/metric_learn) |
| se_resnext50            | [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SE_ResNeXt50) |
| senet_resnet101         | [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SE-Net) |
| senet_resnet50          | [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SE-Net) |
| se-res2net50            | [Res2Net: A New Multi-scale Backbone Architecture](https://arxiv.org/abs/1904.01169) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net) |
| se_resnext50            | [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SE_ResNeXt50) |
| s-ghostnet              | [Greedy Network Enlarging](https://arxiv.org/abs/2108.00177) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/S-GhostNet) |
| sknet                   | [Selective Kernel Networks](https://arxiv.org/abs/1903.06586) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/sknet) |
| resnetv2_101            | [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnetv2) |
| resnetv2_152            | [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnetv2) |
| resnetv2_50             | [Identity Mappings in Deep Residual Networks](https://arxiv.org/abs/1603.05027) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnetv2) |
| resnetv2_50_frn         | [Filter Response Normalization Layer: Eliminating Batch Dependence in the Training of Deep Neural Networks](https://arxiv.org/abs/1911.09737) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnetv2_50_frn) |
| resnext152_64x4d        | [Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnext152_64x4d) |
| hrnet_w48_cls           | [Deep High-Resolution Representation Learning for Visual Recognition](https://arxiv.org/abs/1908.07919) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/HRNetW48_cls) |
| simclr                  | [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/simclr) |
| augvit                  | [Augmented Shortcuts for Vision Transformers](https://arxiv.org/pdf/2106.15941.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/augvit) |
| autoaugment             | [AutoAugment: Learning Augmentation Policies from Data](https://arxiv.org/abs/1805.09501) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/autoaugment) |
| ava_cifar               | [AVA: Adversarial Vignetting Attack against Visual Recognition](https://arxiv.org/abs/2105.05558) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AVA_cifar) |
| ava_hpa                 | [AVA: Adversarial Vignetting Attack against Visual Recognition](https://arxiv.org/abs/2105.05558) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AVA_hpa) |
| pdarts                  | [Progressive DARTS: Bridging the Optimization Gap for NAS in the Wild](https://arxiv.org/abs/1912.10952) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PDarts) |
| pnasnet                 | [Progressive Neural Architecture Search](https://arxiv.org/pdf/1712.00559.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/pnasnet) |
| poseestnet              | [PAMTRI: Pose-Aware Multi-Task Learning for Vehicle Re-Identification Using Highly Randomized Synthetic Data](https://arxiv.org/abs/2005.00673) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PAMTRI/PoseEstNet) |
| protonet                | [Prototypical Networks for Few-shot Learning](https://arxiv.org/abs/1911.11929) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ProtoNet) |
| proxylessnas            | [ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware](https://arxiv.org/abs/1812.00332) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/proxylessnas) |
| ntsnet                  | [Learning to Navigate for Fine-grained Classification](https://arxiv.org/abs/1809.00287) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ntsnet) |
| nfnet                   | [High-Performance Large-Scale Image Recognition Without Normalization](https://arxiv.org/abs/2102.06171) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/NFNet) |
| mnasnet                 | [MnasNet: Platform-Aware Neural Architecture Search for Mobile](https://arxiv.org/abs/1807.11626) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/mnasnet) |
| hour-nas                | [HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens](https://arxiv.org/abs/2005.14446) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/HourNAS) |
| single_path_nas         | [Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours](https://arxiv.org/abs/1904.02877) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/single_path_nas) |
| multitasknet            | [PAMTRI: Pose-Aware Multi-Task Learning for Vehicle Re-Identification Using Highly Randomized Synthetic Data](https://arxiv.org/abs/2005.00673) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PAMTRI/MultiTaskNet) |
| tcn                     | [An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://arxiv.org/abs/1803.01271) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/TCN) |
| vig                     | [Vision GNN: An Image is Worth Graph of Nodes](https://arxiv.org/abs/2206.00272) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ViG) |
| vit_base                | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/vit_base) |
| convnext                | [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)  | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/convnext) |
| wave_mlp                | [An Image Patch is a Wave: Phase-Aware Vision MLP](https://arxiv.org/abs/2111.12294) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/wave_mlp) |
| wideresnet              | [Wide Residual Networks](https://arxiv.org/abs/1605.07146)   | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/wideresnet) |
| tinynet                 | [Model Rubik's Cube: Twisting Resolution, Depth and Width for TinyNets](https://arxiv.org/abs/2010.14819) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tinynet) |
| tnt                     | [TNT: Target-driveN Trajectory Prediction](https://arxiv.org/abs/2008.08294) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/TNT) |
| cait                    | [Going deeper with Image Transformers](https://arxiv.org/abs/2103.17239) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/cait) |
| ssc_resnet50            | [Comatch: Semi-supervised learning with contrastive graph regularization](https://arxiv.org/abs/2011.11183) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssc_resnet50) |
| snn_mlp                 | [Brain-inspired Multilayer Perceptron with Spiking Neurons](https://arxiv.org/abs/2203.14679) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/snn_mlp) |
| relationnet             | [Learning to Compare: Relation Network for Few-Shot Learning](https://arxiv.org/abs/1711.06025) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/relationnet) |
| cbam                    | [CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/CBAM) |
| cct                     | [Escaping the Big Data Paradigm with Compact Transformers](https://arxiv.org/abs/2104.05704) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/cct) |
| drnet                   | [Dynamic Resolution Network](https://arxiv.org/abs/2106.02898) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DRNet) |
| fda-bnn                 | [Learning Frequency Domain Approximation for Binary Neural Networks](https://arxiv.org/abs/2103.00841) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FDA-BNN) |
| fishnet99               | [FishNet: a versatile backbone for image, region, and pixel level prediction](https://arxiv.org/abs/1901.03495) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/fishnet99) |
| genet_res50             | [Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks](https://arxiv.org/abs/1810.12348) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/GENet_Res50) |
| glore_res200            | [Graph-Based Global Reasoning Networks](https://arxiv.org/abs/1811.12814) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/glore_res) |
| glore_res50             | [Graph-Based Global Reasoning Networks](https://arxiv.org/abs/1811.12814) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/glore_res) |
| hardnet                 | [HarDNet: A Low Memory Traffic Network](https://arxiv.org/abs/1909.00948) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/hardnet) |
| ibnnet                  | [Two at Once: Enhancing Learning and Generalization Capacities via IBN-Net](https://arxiv.org/abs/1807.09441) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ibnnet) |
| isynet                  | [ISyNet: Convolutional Neural Networks design for AI accelerator](https://arxiv.org/abs/2109.01932) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ISyNet) |
| ivpf                    | [iVPF: Numerical Invertible Volume Preserving Flow for Efficient Lossless Compression](https://arxiv.org/abs/2103.16211) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ivpf) |
| meta-baseline           | [Meta-Baseline: Exploring Simple Meta-Learning for Few-Shot Learning](https://arxiv.org/abs/2003.04390) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/meta-baseline) |
| maml                    | [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks](https://arxiv.org/abs/1703.03400) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/MAML) |
| leo                     | [Meta-Learning with Latent Embedding Optimization](https://arxiv.org/abs/1807.05960) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/LEO) |
| auto-slim               | [AutoSlim: Towards One-Shot Architecture Search for Channel Numbers](https://arxiv.org/abs/1903.11728) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AutoSlim) |
| dem                     | [Learning a Deep Embedding Model for Zero-Shot Learning](https://arxiv.org/abs/1611.05088) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/dem) |
| triplet_loss_resnet50   | [Beyond triplet loss: A deep quadruplet network for person re-identification](https://arxiv.org/abs/1503.03832) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/metric_learn) |

#### Detection

| model                   | paper                                                        |                      vanilla mindspore                      |
| :---------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| rcnn                    | [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/rcnn) |
| cascadercnn             | [Cascade R-CNN: Delving into High Quality Object Detection](https://arxiv.org/abs/1712.00726) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/CascadeRCNN) |
| retinanet_resnet101 | [focal loss for dense object detection](https://arxiv.org/pdf/1708.02002.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/retinanet_resnet101)|
| retinanet_resnet152 | [focal loss for dense object detection](https://arxiv.org/pdf/1708.02002.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/retinanet_resnet152)|
| ssd_ghostnet            | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_ghostnet) |
| ssd_inception_v2        | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_inception_v2) |
| ssd_inceptionv2         | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_inceptionv2) |
| ssd_mobilenetv2         | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_mobilenetV2) |
| ssd_mobilenetv2_fpnlite | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_mobilenetV2_FPNlite) |
| ssd_resnet_34           | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_resnet_34) |
| ssd_resnet34            | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_resnet34) |
| ssd_resnet50            | [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ssd_resnet50) |
| darknet53               | [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/darknet53) |
| yolov3_resnet18         | [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/yolov3_resnet18) |
| yolov3_tiny             | [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/yolov3_tiny) |
| nas-fpn                 | [NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection](https://arxiv.org/abs/1904.07392) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/nas-fpn) |
| faster_rcnn_dcn         | • [Deformable convnets v2: More deformable, better results](https://arxiv.org/abs/1811.11168)<br/>•[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/faster_rcnn_dcn) |
| res2net_faster_rcnn     | [Faster R-CNN: towards real-time object detection with region proposal networks](https://arxiv.org/abs/1506.01497) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net_faster_rcnn)|
| res2net_yolov3          | [YOLOv3: an incremental improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net_yolov3)|
| u2net                   | [U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection](https://arxiv.org/abs/2005.09007) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/u2net) |
| deepid                  | [Deep Learning Face Representation from Predicting 10,000 Classes](https://openaccess.thecvf.com/content_cvpr_2014/papers/Sun_Deep_Learning_Face_2014_CVPR_paper.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DeepID) |
| detr                    | [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/detr) |
| efficientdet_d0         | [EfficientDet: Scalable and Efficient Object Detection](https://arxiv.org/abs/1911.09070) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/EfficientDet_d0) |
| lightcnn                | [A Light CNN for Deep Face Representation with Noisy Labels](https://arxiv.org/abs/1511.02683) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/LightCNN) |
| centernet               | [Objects as points](https://arxiv.org/pdf/1904.07850.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/centernet)|
| centernet_det           | [Objects as points](https://arxiv.org/pdf/1904.07850.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/centernet_det)|
| centernet_resnet101     | [Objects as points](https://arxiv.org/pdf/1904.07850.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/centernet_resnet101)|
| centernet_resnet50_v1   | [Objects as points](https://arxiv.org/pdf/1904.07850.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/centernet_resnet50_v1)|
| m2det                    | [M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network](https://arxiv.org/abs/1811.04533) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/m2det) |
| rfcn                    | [R-FCN: object detection via region-based fully convolutional networks](https://arxiv.org/pdf/1605.06409.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/rfcn)|
| spnas                   | [Serial-to-parallel backbone search for object detection](https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_SP-NAS_Serial-to-Parallel_Backbone_Search_for_Object_Detection_CVPR_2020_paper.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Spnas)|
| refine_det              | [Single-shot refinement neural network for object detection](https://arxiv.org/pdf/1711.06897.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/RefineDet)|
| egnet                   | [EGNet: edge guidance network for salient object detection](https://arxiv.org/abs/1908.08297) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/EGnet)|
| pagenet                 | [Salient object detection with pyramid attention and salient edges](https://www.researchgate.net/publication/332751907_Salient_Object_Detection_With_Pyramid_Attention_and_Salient_Edges) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PAGENet)|
| ras                     | [Reverse attention-based residual network for salient object detection](https://ieeexplore.ieee.org/abstract/document/8966594) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ras)|
| hed                     | [Holistically-nested edge detection](https://arxiv.org/abs/1504.06375) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/hed)|

#### Segmentation

| model | paper | vanilla mindspore |
|:-     | :-      | :-:  |
| 3d densenet              | [Skip-connected 3D DenseNet for volumetric infant brain MRI segmentation](https://www.sciencedirect.com/science/article/abs/pii/S1746809419301946)  |  [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/3D_DenseNet)           |
| 3d cnn                   | [MRI tumor segmentation with densely connected 3D CNN](https://arxiv.org/abs/1802.02427)  |  [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/3dcnn)           |
| pspnet                   | [Pyramid Scene Parsing Network](https://arxiv.org/abs/1612.01105) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PSPNet) |
| fastscnn                 | [Fast-SCNN: Fast Semantic Segmentation Network](https://arxiv.org/abs/1902.04502)  | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/fastscnn) |
| fcn8s                    | [Fully convolutional networks for semantic segmentation](https://arxiv.org/abs/1411.4038) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FCN8s) |
| adelaide_ea              | [Fast Neural Architecture Search of Compact Semantic Segmentation Models via Auxiliary Cells](https://arxiv.org/abs/1810.10804) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/adelaide_ea) |
| auto-deeplab             | [Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation](https://arxiv.org/abs/1901.02985v2) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Auto-DeepLab) |
| nnunet                   | [nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation](https://www.nature.com/articles/s41592-020-01008-z) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/nnUNet) |
| ddm                      | [Semi-Supervised Domain Adaptation based on Dual-level Domain Mixing for Semantic Segmentation](https://arxiv.org/abs/2103.04705) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DDM) |
| ddrnet                   | [Deep Dual-resolution Networks for Real-time and Accurate Semantic Segmentation of Road Scenes](https://arxiv.org/abs/2101.06085) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DDRNet) |
| vnet                     | [V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation](https://arxiv.org/abs/1606.04797) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/vnet) |
| dgcnet_res101            | [Dual graph convolutional network for semantic segmentation](https://arxiv.org/abs/1909.06121v3) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/dgcnet_res101) |
| enet                     | [ENet: A deep neural network architecture for real-time semantic segmentation](https://arxiv.org/abs/1606.02147) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/E-NET) |
| icnet                    | [ICNet for Real-Time Semantic Segmentation on High-Resolution Images](https://arxiv.org/abs/1704.08545) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ICNet) |
| hrnetw48_seg             | [High-Resolution Representations for Labeling Pixels and Regions](https://arxiv.org/abs/1904.04514)  |[link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/HRNetW48_seg) |
| res2net_deeplabv3| [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/abs/1706.05587) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/res2net_deeplabv3) |
| unet3+                   | [UNET 3+: A FULL-SCALE CONNECTED UNET FOR MEDICAL IMAGE SEGMENTATION](https://arxiv.org/abs/2004.08790) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/UNet3+) |
| yolact++                 | [YOLACT++: Better Real-time Instance Segmentation](https://arxiv.org/abs/1912.06218) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Yolact++) |
| dlinknet                 | [D-LinkNet: LinkNet with Pretrained Encoder and Dilated Convolution for High Resolution Satellite Imagery Road Extraction](https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w4/Zhou_D-LinkNet_LinkNet_With_CVPR_2018_paper.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/dlinknet) |
| erfnet                  | [ERFNet: Efficient Residual Factorized ConvNet for Real-Time Semantic Segmentation](https://ieeexplore.ieee.org/document/8063438) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/erfnet) |
| semantic human matting                | [Semantic Human Matting](https://arxiv.org/pdf/1809.01354.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SemanticHumanMatting) |

#### Face

| model                      | paper                                                        |                      vanilla mindspore                       |
| :------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| faceboxes                  | [FaceBoxes: A CPU Real-time Face Detector with High Accuracy](https://arxiv.org/abs/1708.05234) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/faceboxes) |
| facedetection              | [YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FaceDetection) |
| maskedfacerecognition      | [Masked Face Recognition with Latent Part Detection](https://dl.acm.org/doi/10.1145/3394171.3413731) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/MaskedFaceRecognition) |
| facenet                    | [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FaceNet) |
| facerecognition            | [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FaceRecognition) |
| lresnet100e_ir             | [ArcFace: Additive Angular Margin Loss for Deep Face Recognition](https://arxiv.org/abs/1801.07698v1) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/lresnet100e_ir) |
| centerface              | [CenterFace: Joint Face Detection and Alignment Using Face as Point](https://arxiv.org/abs/1911.03599) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/centerface) |
| sphereface              | [SphereFace: Deep Hypersphere Embedding for Face Recognition](https://arxiv.org/abs/1704.08063) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/sphereface) |
| face-attribute          | [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FaceAttribute) |
| face-quality-assessment | [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FaceQualityAssessment) |

#### OCR

| model              | paper                                                        |                      vanilla mindspore                       |
| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| east               | [EAST: An Efficient and Accurate Scene Text Detector](https://arxiv.org/abs/1704.03155) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/east) |
| psenet             | [Shape Robust Text Detection with Progressive Scale Expansion Network](https://arxiv.org/abs/1806.02559) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/psenet) |
| advanced_east      | [EAST: An Efficient and Accurate Scene Text Detector](https://arxiv.org/abs/1704.03155) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/advanced_east) |
| textfusenet        | [TextFuseNet: Scene Text Detection with Richer Fused Features](https://www.ijcai.org/Proceedings/2020/72) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/textfusenet) |
| cnnctc             | [What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis](https://arxiv.org/abs/1904.01906) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/cnnctc) |
| crnn_seq2seq_ocr   | [Robust Scene Text Recognition with Automatic Rectification](https://arxiv.org/abs/1603.03915) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/crnn_seq2seq_ocr) |
| essay-recogination | [OrigamiNet: Weakly-Supervised, Segmentation-Free, One-Step, Full Page Text Recognition by learning to unfold](https://arxiv.org/abs/2006.07491) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/essay-recogination) |

#### Anomaly Detection

| model              | paper                                                        |                      vanilla mindspore                       |
| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| patch_core               | [Towards Total Recall in Industrial Anomaly Detection](https://arxiv.org/abs/2106.08265) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PatchCore) |
| ssim-ae            | [Improving Unsupervised Defect Segmentation by Applying Structural Similarity To Autoencoders](https://www.researchgate.net/publication/326222902) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SSIM-AE) |
| stpm            | [Student-Teacher Feature Pyramid Matching for Unsupervised Anomaly Detection](https://arxiv.org/pdf/2103.04257v2.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/STPM) |

#### Video

| model            | paper                                                        |                      vanilla mindspore                       |
| :--------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| c3d              | [Learning Spatiotemporal Features with 3D Convolutional Networks](https://arxiv.org/pdf/1412.0767.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/C3D) |
| adnet            | [Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning](https://openaccess.thecvf.com/content_cvpr_2017/papers/Yun_Action-Decision_Networks_for_CVPR_2017_paper.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ADNet) |
| attentioncluster | [Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification](https://arxiv.org/abs/1711.09550) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AttentionCluster) |
| ecolite          | [ECO: Efficient Convolutional Network for Online Video Understanding](https://arxiv.org/abs/1804.09066) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ecolite) |
| fairmot          | [FairMOT: On the Fairness of Detection and Re-Identification in Multiple Object Tracking](https://arxiv.org/abs/2004.01888) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/fairmot) |
| i3d              | [Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset](https://arxiv.org/abs/1705.07750) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/I3D) |
| jde              | [Towards Real-Time Multi-Object Tracking](https://arxiv.org/abs/1909.12605) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/JDE) |
| r2plus1d         | [A Closer Look at Spatiotemporal Convolutions for Action Recognition](https://arxiv.org/abs/1711.11248) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/r2plus1d) |
| rbpn             | [Recurrent Back-Projection Network for Video Super-Resolution](https://arxiv.org/abs/1903.10128) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/rbpn) |
| resnet3d         | [Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?](https://arxiv.org/abs/2004.04968) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/resnet3d) |
| siamfc           | [Fully-Convolutional Siamese Networks for Object Tracking](https://arxiv.org/abs/1606.09549) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SiamFC) |
| siamrpn          | [High Performance Visual Tracking with Siamese Region Proposal Network](https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/siamRPN) |
| slowfast         | [SlowFast Networks for Video Recognition](https://arxiv.org/abs/1812.03982) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/slowfast) |
| stnet            | [StNet: Local and Global Spatial-Temporal Modeling for Action Recognition](https://arxiv.org/abs/1811.01549) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/stnet) |
| tracktor         | [Tracking without bells and whistles](https://arxiv.org/abs/1903.05625) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tracktor) |
| tracktor++       | [Tracking without bells and whistles](https://arxiv.org/abs/1903.05625) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tracktor++) |
| trn              | [Temporal Relational Reasoning in Videos](https://arxiv.org/abs/1711.08496) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/trn) |
| tsm              | [TSM: Temporal Shift Module for Efficient Video Understanding](https://arxiv.org/abs/1811.08383) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tsm) |
| tsn              | [Temporal Segment Networks: Towards Good Practices for Deep Action Recognition](https://arxiv.org/abs/1608.00859) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tsn) |
| predrnn++        | [PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning](https://arxiv.org/abs/1804.06300) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/predrnn++) |
| deepsort         | [Simple Online and Realtime Tracking](https://arxiv.org/abs/1602.00763) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Deepsort) |
| flownet2         | [FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks](https://arxiv.org/abs/1612.01925) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/flownet2) |
| ArtTrack         | [Arttrack: articulated multi-person tracking in the wild](https://arxiv.org/abs/1612.01465) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ArtTrack)|
| osvos            | [One-Shot Video Object Segmentation](https://arxiv.org/abs/1611.05198) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/OSVOS) |

#### Image Editing

| model                       | paper                                                        |                      vanilla mindspore                       |
| :-------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| learning to see in the dark | [Learning to See in the Dark](https://arxiv.org/abs/1805.01934) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/LearningToSeeInTheDark) |
| dncnn                       | [Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising](https://arxiv.org/abs/1608.03981) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/dncnn) |
| mimo-unet                   | [Rethinking Coarse-to-Fine Approach in Single Image Deblurring](https://arxiv.org/abs/2108.05054) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/MIMO-UNet) |
| neighbor2neighbor           | [Neighbor2Neighbor: Self-Supervised Denoising from Single Noisy Images](https://arxiv.org/abs/2101.02824) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Neighbor2Neighbor) |
| brdnet                      | [Image denoising using deep CNN with batch renormalization](https://www.sciencedirect.com/science/article/abs/pii/S0893608019302394) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/brdnet) |
| rdn                         | [Residual Dense Network for Image Super-Resolution](https://arxiv.org/abs/1802.08797) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/RDN) |
| srcnn                       | [Image Super-Resolution Using Deep Convolutional Networks](https://arxiv.org/abs/1501.00092) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/srcnn) |
| wdsr                        | [Wide Activation for Efficient and Accurate Image Super-Resolution](https://arxiv.org/abs/1808.08718) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/wdsr) |
| rcan                        | [Image Super-Resolution Using Very Deep Residual Channel Attention Networks](https://arxiv.org/abs/1807.02758) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/RCAN) |
| rednet30                    | [Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections](https://arxiv.org/pdf/1603.09056.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/REDNet30) |
| irn                         | [Invertible Image Rescaling](https://arxiv.org/abs/2005.05650v1) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/IRN) |
| lite-hrnet                  | [Lite-HRNet: A Lightweight High-Resolution Network](https://arxiv.org/abs/2104.06403) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/lite-hrnet) |
| sr_ea                       | [Neural component search for single image super-resolution](https://www.sciencedirect.com/science/article/abs/pii/S0923596522000583) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/sr_ea) |
| srgan                       | [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network](https://arxiv.org/abs/1609.04802) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SRGAN) |
| csd                         | [Towards Compact Single Image Super-Resolution via Contrastive Self-distillation](https://arxiv.org/abs/2105.11683) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/csd) |
| dbpn                        | [Deep Back-Projection Networks For Super-Resolution](https://arxiv.org/abs/1803.02735) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DBPN) |
| esr_ea                      | [Efficient Residual Dense Block Search for Image Super-Resolution](https://arxiv.org/abs/1909.11409) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/esr_ea) |
| esrgan                      | [ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks](https://arxiv.org/abs/1809.00219) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ESRGAN) |
| stargan                     | [StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation](https://arxiv.org/abs/1711.09020) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/StarGAN) |
| stgan                       | [STGAN: A Unified Selective Transfer Network for Arbitrary Image Attribute Editing](https://arxiv.org/abs/1904.09709) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/STGAN) |
| u-gat-it                    | [U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation](https://arxiv.org/abs/1907.10830) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/U-GAT-IT) |
| pgan                        | [progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PGAN) |
| pix2pix                     | [Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Pix2Pix) |
| singan                      | [SinGAN: Learning a Generative Model from a Single Natural Image](https://arxiv.org/abs/1905.01164) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/SinGAN) |
| gan                         | [Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/gan) |
| hi face gan                 | [HiFaceGAN: Face Renovation via Collaborative Suppression and Replenishment](https://arxiv.org/abs/2005.05005) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/HiFaceGAN) |
| ipt                         | [Pre-Trained Image Processing Transformer](https://arxiv.org/abs/2012.00364) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/IPT) |
| ctsdg                       | [AImage Inpainting via Conditional Texture and Structure Dual Generation](https://arxiv.org/abs/2108.09760) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/CTSDG) |
| cgan                        | [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/CGAN) |
| dcgan                       | [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/dcgan) |
| index net                   | [Indices Matter: Learning to Index for Deep Image Matting](https://arxiv.org/abs/1908.00672) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/IndexNet) |
| fcanet                      | [FcaNet: Frequency Channel Attention Networks](https://arxiv.org/abs/2012.11879) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/FCANet) |
| ap drawing gan              | [APDrawingGAN: Generating Artistic Portrait Drawings from Face Photos with Hierarchical GANs](https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_APDrawingGAN_Generating_Artistic_Portrait_Drawings_From_Face_Photos_With_Hierarchical_CVPR_2019_paper.html) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/APDrawingGAN) |
| arbitrary style transfer    | [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization](https://arxiv.org/abs/1703.06868) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ArbitraryStyleTransfer) |
| aecrnet                     | [Contrastive Learning for Compact Single Image Dehazing](https://arxiv.org/abs/2104.09367) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/aecrnet) |
| attgan                      | [AttGAN: Facial Attribute Editing by Only Changing What You Want](https://arxiv.org/abs/1711.10678) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AttGAN) |
| nima                        | [NIMA: Neural Image Assessment](https://arxiv.org/abs/1709.05424) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/nima) |
| nima_vgg16                  | [NIMA: Neural Image Assessment](https://arxiv.org/abs/1709.05424) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/nima_vgg16) |
| pix2pix_hd                  | [High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs](https://arxiv.org/abs/1711.11585) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Pix2PixHD) |
| wgan-gp                 | [Improved Training of Wasserstein GANs](https://arxiv.org/pdf/1704.00028v3.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/WGAN_GP) |

#### Re-id

| model              | paper                                                        |                      vanilla mindspore                       |
| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| reidstrongbaseline | [A Strong Baseline and Batch Normalization Neck for Deep Person Re-identification](https://arxiv.org/abs/1906.08332) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ReIDStrongBaseline) |
| vehiclenet         | [VehicleNet: Learning Robust Visual Representation for Vehicle Re-identification)](https://arxiv.org/abs/2004.06305) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/VehicleNet) |
| osnet              | [Omni-Scale Feature Learning for Person Re-Identification)](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9011001) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/osnet) |
| mgn                | [Learning Discriminative Features with Multiple Granularities for Person Re-Identification)](https://arxiv.org/abs/1804.01438v1) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/MGN) |
| mvd                | [Farewell to Mutual Information: Variational Distillation for Cross-Modal Person Re-Identification)](https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Farewell_to_Mutual_Information_Variational_Distillation_for_Cross-Modal_Person_Re-Identification_CVPR_2021_paper.html) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/MVD) |
| alignedreid        | [AlignedReID: Surpassing Human-Level Performance in Person Re-Identification)](https://arxiv.org/abs/1711.08184) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AlignedReID) |
| alignedreid++      | [AlignedReID++: Dynamically matching local information for person re-identification)](https://www.sciencedirect.com/science/article/pii/S0031320319302031) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AlignedReID++) |
| ddag               | [Dynamic Dual-Attentive Aggregation Learning for Visible-Infrared Person Re-Identification)](https://arxiv.org/abs/2007.09314) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DDAG) |

#### Pose

| model             | paper                                                        |                      vanilla mindspore                       |
| :---------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| simple_baselines  | [Simple Baselines for Human Pose Estimation and Tracking](https://arxiv.org/abs/1804.06208) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/simple_baselines) |
| stacked_hourglass | [Stacked Hourglass Networks for Human Pose Estimation](https://arxiv.org/abs/1603.06937) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/StackedHourglass) |
| alphapose         | [AlphaPose: Whole-Body Regional Multi-Person Pose Estimation and Tracking in Real-Time](https://arxiv.org/abs/2211.03375) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/AlphaPose) |
| simple_pose       | [Simple baselines for human pose estimation and tracking](https://arxiv.org/abs/1804.06208) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/simple_pose)|

#### 3D

| model        | paper                                                        |                      vanilla mindspore                       |
| :----------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| cmr          | [Convolutional Mesh Regression for Single-Image Human Shape Reconstruction](https://arxiv.org/abs/1905.03244) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/cmr) |
| decomr       | [3D Human Mesh Regression with Dense Correspondence](https://arxiv.org/abs/2006.05734) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DecoMR) |
| deeplm       | [DeepLM: Large-scale Nonlinear Least Squares on Deep Learning Frameworks using Stochastic Domain Decomposition](https://ieeexplore.ieee.org/document/9577879) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/3d/DeepLM) |
| eppmvsnet    | [EPP-MVSNet: Epipolar-assembling based Depth Prediction for Multi-view Stereo](https://ieeexplore.ieee.org/document/9711376) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/eppmvsnet) |
| pointpillars | [PointPillars: Fast Encoders for Object Detection from Point Clouds](https://arxiv.org/abs/1812.05784) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/pointpillars) |
| oct_squeeze | [Octsqueeze: Octree-structured entropy model for lidar compression](https://arxiv.org/abs/2005.07178) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/OctSqueeze) |
| unet3d  | [Unet3D: Learning Dense Volumetric Segmentation from Sparse Annotation](http://arxiv.org/abs/1606.06650) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/Unet3d) |

#### Multi Modal

| model       | paper                                                        |                      vanilla mindspore                       |
| :---------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| opt         | [OPT: Omni-Perception Pre-Trainer for Cross-Modal Understanding and Generation](https://arxiv.org/abs/2107.00249) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/mm/opt) |
| tokenfusion | [Multimodal Token Fusion for Vision Transformers](https://arxiv.org/abs/2204.08721) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/TokenFusion) |
| wukong      | [Wukong: A 100 Million Large-scale Chinese Cross-modal Pre-training Benchmark](https://arxiv.org/abs/2202.06767) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/mm/wukong) |

#### Others

| model   | paper                                                        |                      vanilla mindspore                       |
| :------ | :----------------------------------------------------------- | :----------------------------------------------------------: |
| depthNet | [Depth Map Prediction from a Single Image using a Multi-Scale Deep Network](https://arxiv.org/abs/1406.2283) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/DepthNet) |
| pwcnet   | [PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume](https://arxiv.org/pdf/1709.02371.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PWCNet) |
| midas   | [Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer](https://arxiv.org/abs/1907.01341) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/midas) |
| mcnn    | [Single-Image Crowd Counting via Multi-Column Convolutional Neural Network](https://ieeexplore.ieee.org/document/7780439) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/MCNN) |
| posenet | [PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization](https://arxiv.org/abs/1505.07427) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/PoseNet) |
| stgcn   | [Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting](https://arxiv.org/abs/1709.04875) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/stgcn) |
| tgcn               | [T-GCN: A Temporal Graph ConvolutionalNetwork for Traffic Prediction](https://arxiv.org/abs/1811.05320) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tgcn) |
| tall               | [TALL: Temporal Activity Localization via Language Query](https://arxiv.org/abs/1705.02101) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/tall) |
| delf               | [Large-Scale Image Retrieval with Attentive Deep Local Features](https://arxiv.org/abs/1612.06321) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/delf) |
| pcb_rpp            | [Beyond Part Models: Person Retrieval with Refined Part Pooling (and a Strong Convolutional Baseline)](https://arxiv.org/abs/1711.09349) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/pcb_rpp) |
| manidp             | [Manifold Regularized Dynamic Network Pruning](https://arxiv.org/abs/2103.05861) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/cv/ManiDP) |

### Speech

| model      | paper                                                        |                      vanilla mindspore                       |
| :--------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| ctcmodel   | [Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks](https://dl.acm.org/doi/abs/10.1145/1143844.1143891) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/audio/ctcmodel) |
| dscnn      | [Hello Edge: Keyword Spotting on Microcontrollers](https://arxiv.org/abs/1711.07128) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/audio/dscnn) |
| fastspeech | [FastSpeech: Fast, Robust and Controllable Text to Speech](https://arxiv.org/abs/1905.09263) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/audio/FastSpeech) |
| fcn-4      | [Automatic tagging using deep convolutional neural networks](https://arxiv.org/abs/1606.00298) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/audio/fcn-4) |
| jasper     | [Jasper: An End-to-End Convolutional Neural Acoustic Model](https://arxiv.org/abs/1904.03288) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/audio/jasper) |
| wavenet    | [WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/audio/wavenet) |
| speech_transformer | [The Speechtransformer for Large-scale Mandarin Chinese Speech Recognition](https://ieeexplore.ieee.org/document/8682586) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/speech_transformer) |

### Text

| model              | paper                                                        |                      vanilla mindspore                       |
| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| albert             | [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/albert) |
| atae_lstm          | [Attention-based LSTM for Aspect-level Sentiment Classification](https://aclanthology.org/D16-1058/) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/atae_lstm) |
| dam                | [Multi-Turn Response Selection for Chatbots with Deep Attention Matching Network](https://aclanthology.org/P18-1103/) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/dam) |
| gpt2               | [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/gpt2) |
| hake               | [Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction](https://arxiv.org/abs/1911.09419) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/hake) |
| ktnet              | [Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension](https://www.aclweb.org/anthology/P19-1226) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/ktnet) |
| lstm_crf           | [Bidirectional LSTM-CRF Models for Sequence Tagging](https://arxiv.org/abs/1508.01991) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/lstm_crf) |
| luke               | [LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention](https://arxiv.org/abs/2010.01057) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/luke) |
| rotate             | [RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space](https://arxiv.org/abs/1902.10197) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/rotate) |
| senta              | [SKEP: Sentiment Knowledge Enhanced Pre-training for Sentiment Analysis](https://arxiv.org/abs/2005.05635) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/senta) |
| seq2seq            | [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/seq2seq) |
| skipgram           | [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/skipgram) |
| ternarybert        | [TernaryBERT: Distillation-aware Ultra-low Bit BERT](https://arxiv.org/abs/2009.12812) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/ternarybert) |
| tprr               | [Answer Complex Questions: Path Ranker Is All You Need](https://dl.acm.org/doi/abs/10.1145/3404835.3462942) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/tprr) |
| transformer_xl     | [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/transformer_xl) |
| transX             | [Translating Embeddings for Modeling Multi-relational Data](https://proceedings.neurips.cc/paper_files/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/transX) |
| cpm                | [A Large-scale Generative Chinese Pre-trained Language Model](https://arxiv.org/abs/2012.00413) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/cpm) |
| dgu(based on bert) | [Baidu Dialogue General Understanding based on Bert](https://github.com/baidu/Dialogue/tree/master/DGU)| [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/dgu) |
| duconv             | [Proactive Human-Machine Conversation with Explicit Conversation Goals](https://arxiv.org/abs/1906.05572v2) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/duconv) |
| emotect(based on ernie) | [ERNIE: Enhanced Representation through Knowledge Integration](https://arxiv.org/abs/1904.09223)  | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/emotect) |
| ernie              | [ERNIE: Enhanced Representation through Knowledge Integration](https://arxiv.org/abs/1904.09223) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/ernie) |
| fasttext           | [Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/fasttext) |
| gnmt_v2            | [Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation](https://arxiv.org/abs/1609.08144) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/gnmt_v2) |
| mass               | [MASS: Masked Sequence to Sequence Pre-training for Language Generation](https://arxiv.org/abs/1905.02450) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/mass) |
| textcnn            | [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/textcnn) |
| tinybert           | [TinyBERT: Distilling BERT for Natural Language Understanding](https://arxiv.org/abs/1909.10351) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/tinybert) |
| textrcnn           | [Recurrent Convolutional Neural Networks for Text Classification](https://ojs.aaai.org/index.php/AAAI/article/view/9513) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/textrcnn) |
| hypertext          | [HyperText: Endowing FastText with Hyperbolic Geometry](https://arxiv.org/abs/2010.16143) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/nlp/hypertext) |

### Graph

| model     | paper                                                        |                      vanilla mindspore                       |
| :-------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| dgcn      | [Dual Graph Convolutional Networks for Graph-Based Semi-Supervised Classification](https://www.researchgate.net/publication/324514333_Dual_Graph_Convolutional_Networks_for_Graph-Based_Semi-Supervised_Classification) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/gnn/dgcn) |
| sdne      | [Structural Deep Network Embedding](https://dl.acm.org/doi/abs/10.1145/2939672.2939753) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/gnn/sdne) |
| sgcn      | [Signed Graph Convolutional Networks](https://ieeexplore.ieee.org/abstract/document/8594922) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/gnn/sgcn) |
| bgcf      | [A Framework for Recommending Accurate and Diverse Items Using Bayesian Graph Convolutional Neural Networks](https://dl.acm.org/doi/abs/10.1145/3394486.3403254) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/gnn/bgcf) |
| gat       | [Graph Attention Networks](https://arxiv.org/abs/1710.10903) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/gnn/gat) |

### Recommendation

| model          | paper                                                        |                      vanilla mindspore                       |
| :------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| autodis        | [An Embedding Learning Framework for Numerical Features in CTR Prediction](https://arxiv.org/abs/2012.08986) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/autodis) |
| DIEN           | [Deep Interest Evolution Network for Click-Through Rate Prediction](https://arxiv.org/abs/1809.03672) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/DIEN) |
| dlrm           | [Deep Learning Recommendation Model for Personalization and Recommendation Systems](https://arxiv.org/abs/1906.00091) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/dlrm) |
| EDCN           | [Enhancing Explicit and Implicit Feature Interactions via Information Sharing for Parallel Deep CTR Models](https://dl.acm.org/doi/abs/10.1145/3459637.3481915) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/EDCN) |
| Fat-DeepFFM    | [FAT-DeepFFM: Field Attentive Deep Field-aware Factorization Machine](https://arxiv.org/abs/1905.06336) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/Fat-DeepFFM) |
| mmoe           | [Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts](https://www.kdd.org/kdd2018/accepted-papers/view/modeling-task-relationships-in-multi-task-learning-with-multi-gate-mixture-) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/mmoe) |
| deep_and_cross | [Deep & Cross Network for Ad Click Predictions](https://arxiv.org/abs/1708.05123) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/deep_and_cross) |
| fibinet        | [FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction](https://arxiv.org/abs/1905.09433) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/fibinet) |
| naml           | [Neural News Recommendation with Attentive Multi-View Learning](https://arxiv.org/abs/1907.05576) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/naml) |
| ncf            | [Neural Collaborative Filtering](https://arxiv.org/abs/1708.05031) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/recommend/ncf) |

### HPC

| model              | paper                                                        |                      vanilla mindspore                       |
| :----------------- | :----------------------------------------------------------- | :----------------------------------------------------------: |
| deepbsde           | [Pricing Barrier Options with DeepBSDEs](https://arxiv.org/abs/2005.10966) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/hpc/deepbsde) |
| molecular_dynamics | [Deep Potential Molecular Dynamics: a scalable model with the accuracy of quantum mechanics](https://arxiv.org/abs/1707.09571) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/hpc/molecular_dynamics) |
| ocean_model        | [OpenArray v1.0: a simple operator library for the decoupling of ocean modeling and parallel computing](https://gmd.copernicus.org/articles/12/4729/2019/gmd-12-4729-2019.html) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/hpc/ocean_model) |
| pafnucy            | [Development and evaluation of a deep learning model for protein-ligand binding affinity prediction](https://arxiv.org/abs/1712.07042) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/hpc/pafnucy) |
| pfnn               | [A penalty-free neural network method for solving a class of second-order boundary-value problems on complex geometries](https://www.sciencedirect.com/science/article/abs/pii/S0021999120308597) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/hpc/pfnn) |
| pinns              | [Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.](https://www.sciencedirect.com/science/article/abs/pii/S0021999118307125) | [link](https://gitee.com/mindspore/models/tree/r2.0/research/hpc/pinns) |
