# Copyright 2021-2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# =========================================================================

import os
import glob
import numpy as np
import mindspore.dataset as ds
from mindspore.dataset.transforms.transforms import Compose
from src.model_utils.config import config
from src.transform import Dataset, ExpandChannel, LoadData, Orientation, ScaleIntensityRange, RandomCropSamples, OneHot


class ConvertLabel:
    """
    Crop at the center of image with specified ROI size.

    Args:
        roi_size: the spatial size of the crop region e.g. [224,224,128]
        If its components have non-positive values, the corresponding size of input image will be used.
    """

    def operation(self, data):
        """
        Apply the transform to `img`, assuming `img` is channel-first and
        slicing doesn't apply to the channel dim.
        """
        data[data > config.upper_limit] = 0
        data = data - (config.lower_limit - 1)
        data = np.clip(data, 0, config.lower_limit)
        return data

    def __call__(self, image, label):
        label = self.operation(label)
        return image, label


def create_dataset(data_path, seg_path, rank_size=1, rank_id=0, is_training=True):
    seg_files = sorted(glob.glob(os.path.join(seg_path, "*.nii.gz")))
    train_files = [os.path.join(data_path, os.path.basename(seg)) for seg in seg_files]
    train_ds = Dataset(data=train_files, seg=seg_files)
    train_loader = ds.GeneratorDataset(
        train_ds,
        column_names=["image", "seg"],
        num_parallel_workers=4,
        shuffle=is_training,
        num_shards=rank_size,
        shard_id=rank_id,
    )

    if is_training:
        transform_image = Compose(
            [
                LoadData(),
                ExpandChannel(),
                Orientation(),
                ScaleIntensityRange(
                    src_min=config.min_val, src_max=config.max_val, tgt_min=0.0, tgt_max=1.0, is_clip=True
                ),
                RandomCropSamples(roi_size=config.roi_size, num_samples=2),
                ConvertLabel(),
                OneHot(num_classes=config.num_classes),
            ]
        )
    else:
        transform_image = Compose(
            [
                LoadData(),
                ExpandChannel(),
                Orientation(),
                ScaleIntensityRange(
                    src_min=config.min_val, src_max=config.max_val, tgt_min=0.0, tgt_max=1.0, is_clip=True
                ),
                ConvertLabel(),
            ]
        )

    train_loader = train_loader.map(
        operations=transform_image, input_columns=["image", "seg"], num_parallel_workers=12, python_multiprocessing=True
    )
    if not is_training:
        train_loader = train_loader.batch(1)
    return train_loader
