# DBNet

***

Paper: [Real-time Scene Text Detection with Differentiable Binarization](https://arxiv.org/abs/1911.08947)

Label: Text Detection

***

## Introduction

In recent years, segmentation based methods are very popular in scene text detection, because segmentation results can more accurately describe various shapes of scene text, such as curved text. However, post-processing of binarization is essential for segmentation based detection, which converts the probability graph generated by the segmentation method into the boundary box/region of the text. DBNet has proposed a module called differentiable binarization (DB), It can perform the binarization process in the segmentation network. The segmentation network optimized with the DB module can adaptively set the binarization threshold, which not only simplifies the post-processing, but also improves the performance of text detection.

![img](https://user-images.githubusercontent.com/22607038/142791306-0da6db2a-20a6-4a68-b228-64ff275f67b3.png)

## Dataset

Datasets used: [ICDAR2015](<https://rrc.cvc.uab.es/?ch=4&com=downloads>)

- Size: 132M
    - Training Set:
        - image: 88.5M(1000 images)
        - label: 157KB
    - Evaluation Set:
        - image: 43.3M(500 images)
        - label: 244KB
- Data format: image, label

After downloading on the official website, organize the dataset into the following structure:

```text
└─ICDAR2015
    ├─ch4_training_images                                       # train images
    ├─ch4_training_localization_transcription_gt                # train gts
    ├─ch4_test_images                                           # val images
    └─Challenge4_Test_Task1_GT                                  # val gts
```

## Environmental requirements

- Device（Ascend/GPU/CPU）
    - Use Ascend/GPU/CPU as hardware environment. Refer to [MindSpore](https://www.mindspore.cn/install) to install the runtime environment.
- MindSpore >= 1.9

```shell
git clone https://gitee.com/mindspore/models.git
cd models/official/cv/DBNet
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

## BenchMark

### Accuracy

| Model | pretrained Model | config | Train Set | Test Set | Device Num | Epoch | Test Size | Recall | Precision | Hmean | CheckPoint | Graph Train Log |
| ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- |
| DBNet-R18 | [R18](https://download.mindspore.cn/thirdparty/dbnet/resnet18-5c106cde.ckpt) | [cfg](config/dbnet/config_resnet18_1p.yaml) | ICDAR2015 Train | ICDAR2015 Test | 1 | 1200 | 736 | 78.63 | 84.21 | 81.32 | [download]() | [download]() |
| DBNet-R50 | [R50](https://download.mindspore.cn/thirdparty/dbnet/resnet50-19c8e357.ckpt) | [cfg](config/dbnet/config_resnet50_1p.yaml) | ICDAR2015 Train | ICDAR2015 Test | 1 | 1200 | 736 | 81.05 | 88.07 | 84.41 | [download]() | [download]() |
| DBNet-MobileNetv3 | [M3]() | [cfg](config/dbnet/config_mobilenetv3_1p.yaml) | ICDAR2015 Train | ICDAR2015 Test | 1 | 1200 | 736 | 73,.05 | 77.02 | 74.96 | [download]() | [download]() |

### Performance

| device | Model     | dataset   | Params(M) | PyNative train 1P bs=16 FPS | PyNative train 8P bs=8 FPS | PyNative infer FPS | Graph train 1P bs=16 FPS | Graph train 8P bs=8 FPS | Graph infer FPS |
| ------ | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- |
| Ascend | DBNet-R18 | ICDAR2015 |  11.78 M  |  95  |  381  |    -     |   150    |   610   | 40.62  |
|  GPU   | DBNet-R18 | ICDAR2015 |  11.78 M  |  18    |   81     |   -    |  23  |    104 |  30.97  |
| Ascend | DBNet-R50 | ICDAR2015 |  24.28 M  |  59    |   237  |   -     |  100    |   460    |  33.88  |
|  GPU   | DBNet-R50 | ICDAR2015 |  24.28 M  |  15      |   74    |  -    |  20  |  102 |  23.95  |
| Ascend | DBNet-M3 | ICDAR2015 |  1.77 M  |   60  |   241  |   -     |  117    |   550    |  39.11 |
|  GPU   | DBNet-M3 | ICDAR2015 |  1.77 M  |  15      |   75    |  -    |  18.5  |  98 |  30.21 |

This model is greatly affected by data processing, and the performance data on different machines fluctuate greatly. The above data are for reference.

The above data are tested at:

Ascend 910A 32G 8 devices; Operating system: Euler2.8; Memory: 756 G; ARM 96 cores CPU;

GPU v100 PCIE 32G 8 devices; Operating system: Ubuntu 18.04; Memory: 502 G; x86 72 cores CPU.

## Quickly Start

### Parameter file description

```text
    config/config_base.yaml: Common parameter file, data set path, optimizer, training strategy and other parameters are usually set in this file
    config/dbnet/*.yaml: backbone training policy profile with dbnet
    config/dbnet++/*.yaml: backbone training policy profile with dbnet++
```

notice：dbnet/*.yaml and /dbnet++/*.yaml parameters will cover config_base.yaml，Users can reasonably configure according to their needs

Single train backbone resnet18 with ICDAR2015 as an example:

1. Configure training and reasoning data set path in `config/config_base.yaml`, the path need to be an absolute path.

```text
load_mindrecord: True    # Whether to preprocess the data into Mindrecord format, the entire training will be faster
mindrecord_path: "/path/dbnet/dataset"    # The path saved by Mindrecord needs to be an absolute path and only needs to be generated once
train:
    img_dir: /data/ICDAR2015/ch4_training_images
    gt_dir: /data/ICDAR2015/ch4_training_localization_transcription_gt
eval:
    img_dir: /data/ICDAR2015/ch4_test_images
    gt_dir: /data/ICDAR2015/Challenge4_Test_Task1_GT
```

2. Configure backone_ckpt pre-training path in `config/dbnet/config_resnet18_1p.yaml`

```text
backbone:
    backbone_ckpt: "/data/pretrained/resnet18-5c106cde.ckpt"
```

### Run standalone

```shell
bash scripts/run_standalone_train.sh [CONFIG_PATH] [DEVICE_ID] [LOG_NAME](optional)

# standalone train resnet18
bash scripts/run_standalone_train.sh config/dbnet/config_resnet18_1p.yaml 0 db_r18_1p

# standalone train resnet50
bash scripts/run_standalone_train.sh config/dbnet/config_resnet50_1p.yaml 0 db_r50_1p

# standalone train mobilenetv3 large
bash scripts/run_standalone_train.sh config/dbnet/config_mobilenetv3_1p.yaml 0 db_m3_1p
```

### Run distribution

```shell
# Starting with the for loop on Ascend before MindSpore1.8
bash scripts/run_distribution_train_ascend.sh [RANK_TABLE_FILE] [DEVICE_NUM] [CONFIG_PATH]

# After 1.8, on Ascend, like on GPU, can be started using mpirun
bash scripts/run_distribution_train.sh [DEVICE_NUM] [CONFIG_PATH] [LOG_NAME](optional)

# Ascend distribute train 8p resnet18
bash scripts/run_distribution_train.sh 8 config/dbnet/config_resnet18_8p.yaml db_r18_8p

# Ascend distribute train 8p resnet50
bash scripts/run_distribution_train.sh 8 config/dbnet/config_resnet50_8p.yaml db_r50_8p

# Ascend distribute train mobilenetv3 8p large
bash scripts/run_distribution_train.sh 8 config/dbnet/config_mobilenetv3_8p.yaml db_m3_8p
```

### Evaluation

```shell
bash scripts/run_eval.sh [CONFIG_PATH] [CKPT_PATH] [DEVICE_ID] [LOG_NAME](optional)

# eval resnet18
bash scripts/run_eval.sh config/dbnet/config_resnet18_1p.yaml your_ckpt_path 0 eval_r18
```

If you need to modify the device or other configurations, please modify the corresponding items in the configuration file.

## Training

### Run standalone train

```shell
bash scripts/run_standalone_train.sh [CONFIG_PATH] [DEVICE_ID] [LOG_NAME](optional)
# CONFIG_PATH：The configuration file path
# DEVICE_ID：Card number used for training
# LOG_NAME: Directory and logs name for saving results, default is train
```

Executing the above command will run in the background. You can view the results through the [LOG_NAME].txt file

After the training, you can find the checkpoint file in [LOG_NAME].

### Run distribution train

```shell
bash scripts/run_distribution_train.sh [DEVICE_NUM] [CONFIG_PATH] [LOG_NAME](optional)
# DEVICE_NUM：Number of cards used for training
# CONFIG_PATH：The configuration file path
# LOG_NAME: Directory and logs name for saving results, default is distribution_train
```

Executing the above command will run in the background. You can view the results through the [LOG_NAME].txt file.

## resume train

If you want to use the resume training function, you only need to resume in the config file_ Ckpt can be added to the ckpt path training that needs to continue training.

### ModelArts

1. Configure the ModelArts parameter in the config file:

- setting enable_modelarts=True
- Setting OBS dataset path data_url: <path of dataset in OBS>
- Set OBS training return path train_url: <Path of output file in OBS>

2. Referring to [ModelArts](https://support.huaweicloud.com/modelarts/index.html) executing training.

## Online Evaluation

### evaluation

```shell
bash scripts/run_eval.sh [CONFIG_PATH] [CKPT_PATH] [DEVICE_ID] [LOG_NAME](optional)
# CONFIG_PATH: The configuration file path
# CKPT_PATH: The checkpoint path
# DEVICE_ID: Device id used for training
# LOG_NAME: Directory and logs name for saving results, default is eval
```

Executing the above command will run in the background. You can view the results through the [LOG_NAME].txt file.

## Off-line Evaluation

### Export Process

```shell
python export.py --config_path=[CONFIG_PATH] --ckpt_path=[CKPT_PATH]
```

You can find the MINDIR file in current path.

### 310 Inference

Plaese refer to  [MindSpore Inference with C++ Deployment Guide](https://gitee.com/mindspore/models/blob/master/utils/cpp_infer/README_CN.md) to set environment variables.

```shell
bash scripts/run_cpp_infer.sh [MINDIR_PATH] [CONFIG_PATH] [OUTPUT_DIR] [DEVICE_TARGET] [DEVICE_ID]
# MINDIR_PATH: The path of MindIR file
# CONFIG_PATH: The configuration file path
# OUTPUT_DIR: Data preprocessing and result saving path
# DEVICE_TARGET: Should be in [Ascend, GPU, CPU], 310 Inference choose Ascend
# DEVICE_ID: Device id
```

## Disclaimers

Models only provide scripts for downloading and preprocessing public data sets. We do not own these datasets, nor are we responsible for their quality or maintenance. Please ensure that you have the permission to use the datasets under the permission of the datasets. The models trained on these datasets are only used for non-commercial research and teaching purposes.

To the dataset owner: If you do not want to include the data set in MindSpore models or want to update it in any way, we will delete or update all public content as required. Please contact us through Gitee. Thank you for your understanding and contribution to the community.

## Thank

This version of DBNet draws on some excellent open source projects, including:

https://github.com/MhLiao/DB.git

https://gitee.com/yanan0122/dbnet-and-dbnet_pp-by-mind-spore.git

## FAQ

Please refer to [Models FAQ](https://gitee.com/mindspore/models#FAQ) to find some common public questions.

Q: When there is not enough memory or too many threads with WARNING, how to solve it?

A: Adjust the `num_workers`, `prefetch_size`,  `max_rowsize` in configuration file.
Generally, excessive CPU consumption needs to be reduced `num_workers`; Excessive memory consumption needs to be reduced `num_workers`, `prefetch_size` and `max_rowsize`.

Q: What to do if loss does not converge in GPU environment?

A: Setting `mix_precision` to `False` in configuration file.

Q: Why TotalText has dataset interface but no configuration file?

A: TotalText needs to use the pretrained parameters on the SynthText dataset. Currently, no pre-trained parameter file on the SynthText dataset is provided.
