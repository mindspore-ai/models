# Copyright 2022 Huawei Technologies Co., Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
enable_modelarts: False
# Url for modelarts
data_url: ""
train_url: ""
checkpoint_url: ""
# Path for local
data_path: "/cache/data"
output_path: "/cache/train"
load_path: "/cache/checkpoint_path"
device_target: "Ascend"
device_id: 0
run_distribute: 0

# ==============================================================================
# options
in_channels: 80                                                 # input channel size, same as the dim of fbank feature
channels: 1024                                                  # channel size of middle layer feature map
base_lrate: 0.000001                                            # base learning rate of cyclic LR
max_lrate: 0.0001                                               # max learning rate of cyclic LR
momentum: 0.95                                                  # weight decay for optimizer
weight_decay: 0.000002                                          # momentum for optimizer
num_epochs: 3                                                   # training epoch
minibatch_size: 192                                             # batch size
emb_size: 192                                                   # embedding dim
step_size: 65000                                                # steps to achieve max learning rate cyclic LR
class_num: 7205                                                 # speaker num pf voxceleb1&2 
pre_trained: False                                              # if pre-trained model exist

train_data_path: "/Temp/abc/feat_train/"                        # path to fbank training data
keep_checkpoint_max: 20                           
checkpoint_path: "train_ecapa_vox2_full-2_664204.ckpt"          # path to pre-trained model
ckpt_save_dir: "./ckpt/"                                        # path to store train model

# eval
eval_data_path: "/Temp/abc/feat_eval/"                          # path to eval fbank data
veri_file_path: /Temp/abc/feat_eval/veri_test_bleeched.txt      # trials
cut_wav: false                                                  # cut wav to 3s (cut wav to 3s, same as train data)
model_path: "/Temp/abc/ckpt/train_ecapa_vox12-1_660204.ckpt"    # path of eval model
train_norm_path: "/Temp/abc/feat_norm/"                         # fbank data for norm 
score_norm: "s-norm"                                            # if do norm, uncomment this two line
cohort_size: 20000                                              # max number of utts to do norm
npy_file_path: '/Temp/abc/npys/'                                # dir to save intermediate result

# # export option
exp_ckpt_file: './train_ecapa_vox2_full-2_664204.ckpt'
file_name: "ecapatdnn"
file_format: "MINDIR"
length: 301
channel: 80
emb_dir: "output/"
310_data_path: "testdata/"
